{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ca3ac9",
   "metadata": {},
   "source": [
    "# U_former - <font color=\"red\">Deblur</font>\n",
    "***\n",
    "Uformer, an image restoration model, based on Transformer Architecture aims to leverage the capability of self-attention in feature maps at multi-scale resolutions to recover more image details. \n",
    "\n",
    "Deblurring in image restoration refers to the process of mitigating or removing blurriness from a digital image that aims to recover the high-frequency details that were lost due to blurriness, thereby enhancing the clarity and quality of the image. Here we are doing with Motion deblurring techniques, which are designed to specifically address blurriness caused by camera motion. \n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a621c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\YEDHU_PROJECT\\nn_project_uformer\n",
      "D:\\YEDHU_PROJECT\\nn_project_uformer\n",
      "['D:\\\\YEDHU_PROJECT\\\\nn_project_uformer', 'C:\\\\Users\\\\SARATHCHANDRAKUMAR\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\python37.zip', 'C:\\\\Users\\\\SARATHCHANDRAKUMAR\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\DLLs', 'C:\\\\Users\\\\SARATHCHANDRAKUMAR\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\lib', 'C:\\\\Users\\\\SARATHCHANDRAKUMAR\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37', 'C:\\\\venvs\\\\uformer', '', 'C:\\\\venvs\\\\uformer\\\\lib\\\\site-packages', 'C:\\\\venvs\\\\uformer\\\\lib\\\\site-packages\\\\win32', 'C:\\\\venvs\\\\uformer\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\venvs\\\\uformer\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\venvs\\\\uformer\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\SARATHCHANDRAKUMAR\\\\.ipython', 'D:\\\\YEDHU_PROJECT\\\\nn_project_uformer\\\\./development', 'D:\\\\YEDHU_PROJECT\\\\nn_project_uformer\\\\./development']\n",
      "D:\\YEDHU_PROJECT\\nn_project_uformer\\./development/\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "dir_name = os.path.join(notebook_dir)\n",
    "sys.path.append(os.path.join(dir_name, './development'))\n",
    "directory = os.path.join(dir_name, './development/') \n",
    "\n",
    "print(notebook_dir)\n",
    "print(dir_name)\n",
    "print(sys.path)\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5779bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8779c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import utils\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import argparse\n",
    "import options\n",
    "import math\n",
    "\n",
    "from model import Uformer\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from losses import CharbonnierLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.loader import get_training_data, get_validation_data\n",
    "from dataset import get_validation_deblur_data\n",
    "from tqdm import tqdm\n",
    "from timm.utils import NativeScaler\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr_loss\n",
    "from skimage.metrics import structural_similarity as ssim_loss\n",
    "from skimage import img_as_float32, img_as_ubyte\n",
    "from dataset.dataset_denoise import *\n",
    "from dataset.dataset_motiondeblur import *\n",
    "from model import UNet,Uformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e369c66",
   "metadata": {},
   "source": [
    "## Data Preparation \n",
    "The GoPro dataset is made into custom  made train, validation and test datasets patches using [custom_dataset_deblur](\"D:\\YEDHU_PROJECT\\CODE\\deployment\\custom_dataset_deblur.py\"). The generated data sets are then stored in `/deployment/dataset/deblur/GoPro/customized_dataset` with separate folders and each of the datasets contains a ground_truth and an input folders.\n",
    "\n",
    "## Setting Directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f194099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_weights_path=os.path.join(directory,\"./models/pretrained/deblur/model_best.pth\")\n",
    "train_dir=os.path.join(directory,\"./datasets/deblur/GoPro/customized_dataset/train\")\n",
    "val_dir=os.path.join(directory,\"./datasets/deblur/GoPro/customized_dataset/val\")\n",
    "test_dir=os.path.join(directory,\"./datasets/deblur/GoPro/customized_dataset/test\")\n",
    "model_dir=os.path.join(directory,\"./models/training/deblur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71159582",
   "metadata": {},
   "source": [
    "## Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "002bc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ps = 128   # train patch size\n",
    "val_ps = 128   # validation patch size\n",
    "test_ps = 128   # test patch size\n",
    "dd_in = 3   # dd_in\n",
    "optimizer = 'adamw'\n",
    "lr_initial = 0.0002   # learing rate\n",
    "weight_decay = 0.02\n",
    "warmup_epochs = 2\n",
    "pretrain_weights = pretrain_weights_path\n",
    "train_workers = 4\n",
    "eval_workers = 4\n",
    "checkpoint = 50\n",
    "batch_size = 1\n",
    "nepoch = 3   # number of epochs for training\n",
    "resume = True\n",
    "do_validation= True\n",
    "warmup = True\n",
    "embed_dim=32\n",
    "win_size=8\n",
    "checkpoint = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af032c",
   "metadata": {},
   "source": [
    "## Dataset loading \n",
    "`Training`,`validation` and `testing` datasets are loaded using `get_training_data` and `get_validation_deblur_data`. The data is organized into batches using the DataLoader class, which provides parallel data loading and preprocessing. For the training dataset, shuffling is enabled to enhance randomness during training. For validation, shuffling is turned off to ensure consistent evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61bf47ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading datasets\n",
      "Size of Train Dataset:40\n",
      "Size of Validation Dataset:40\n",
      "Size of Test Dataset:40 \n"
     ]
    }
   ],
   "source": [
    "print('===> Loading datasets')\n",
    "img_options_train = {'patch_size':train_ps}\n",
    "train_dataset = get_training_data(train_dir, img_options_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True,\n",
    "                          num_workers=train_workers, \n",
    "                          pin_memory=False, \n",
    "                          drop_last=False)\n",
    "img_options_val = {'patch_size':val_ps}\n",
    "val_dataset = get_validation_deblur_data(val_dir, img_options_val)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=eval_workers, \n",
    "                        pin_memory=False, \n",
    "                        drop_last=False)\n",
    "test_dataset = get_validation_deblur_data(test_dir)\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False, \n",
    "                         drop_last=False)\n",
    "len_trainset = train_dataset.__len__()\n",
    "len_valset = val_dataset.__len__()\n",
    "len_testset = test_dataset.__len__()\n",
    "print(\"Size of Train Dataset:{}\\nSize of Validation Dataset:{}\\nSize of Test Dataset:{} \"\n",
    "      .format(len_trainset,len_valset,len_testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5edc370",
   "metadata": {},
   "source": [
    "## Loading Model Architecture\n",
    "Loading the Uformer architecture with the hyper parameters into model_restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6773b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_restoration_deblur = Uformer(img_size=train_ps,\n",
    "                            embed_dim=32,\n",
    "                            win_size=8,\n",
    "                            token_projection='linear',\n",
    "                            token_mlp='leff',\n",
    "                            depths=[1, 2, 8, 8, 2, 8, 8, 2, 1],\n",
    "                            modulator=True,\n",
    "                            dd_in=dd_in).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9da95",
   "metadata": {},
   "source": [
    "## Setting Optimizer & Loss\n",
    "Creating an AdamW optimizer for model parameter optimization and setting CharbonnierLoss as the loss function and move it to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "217204f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model_restoration_deblur.parameters(), \n",
    "                            lr=lr_initial, betas=(0.9, 0.999),\n",
    "                            eps=1e-8, \n",
    "                            weight_decay=weight_decay)\n",
    "criterion = CharbonnierLoss().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5efe3fa",
   "metadata": {},
   "source": [
    "## Setting Scheduler\n",
    "If the `warmup` flag is enabled, a combination of warmup and cosine annealing to gradually adjust the learning rate. Alternatively, if the `warmup` flag is not enabled,a step-based strategy using the StepLR scheduler is using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89c2088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using warmup and cosine strategy!\n"
     ]
    }
   ],
   "source": [
    "if warmup:\n",
    "    print(\"Using warmup and cosine strategy!\")\n",
    "    warmup_epochs = warmup_epochs\n",
    "    scheduler_cosine = optim.lr_scheduler.CosineAnnealingLR(optimizer, nepoch-warmup_epochs, eta_min=1e-6)\n",
    "    scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=warmup_epochs, after_scheduler=scheduler_cosine)\n",
    "    scheduler.step()\n",
    "else:\n",
    "    step = 50\n",
    "    print(\"Using StepLR,step = {}!\".format(step))\n",
    "    scheduler = StepLR(optimizer, step_size=step, gamma=0.5)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc346102",
   "metadata": {},
   "source": [
    "##  Setting Resume\n",
    "If the `resume` option is enabled, the training is resume from the checkpoint. This involves loading the model's previous state, optimizer parameters, and the starting epoch and the learning rate scheduler is updated to reflect the training progress up to the resumed epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c84e5947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume from D:\\YEDHU_PROJECT\\nn_project_uformer\\./development/./models/pretrained/deblur/model_best.pth\n",
      "start epoch:  2966\n",
      "===> Resuming Training with learning rate: 0.0002\n",
      "end epoch: 2968\n"
     ]
    }
   ],
   "source": [
    "if resume: \n",
    "    path_chk_rest = pretrain_weights \n",
    "    print(\"Resume from \"+path_chk_rest)\n",
    "    utils.load_checkpoint(model_restoration_deblur,path_chk_rest) \n",
    "    start_epoch = utils.load_start_epoch(path_chk_rest) + 1 \n",
    "    lr = utils.load_optim(optimizer, path_chk_rest)\n",
    "    print(\"start epoch: \",start_epoch)\n",
    "    for i in range(1, start_epoch):\n",
    "        scheduler.step()\n",
    "    new_lr = scheduler.get_last_lr()[0]\n",
    "    print(\"===> Resuming Training with learning rate:\", new_lr)\n",
    "    nepoch=start_epoch+nepoch-1\n",
    "    print(f\"end epoch: {nepoch}\")\n",
    "else:\n",
    "    start_epoch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4125f5d",
   "metadata": {},
   "source": [
    "## Setting Data Parallel\n",
    "Configure the model to use data parallelism for efficient utilization of multiple GPUs for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2270e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_restoration_deblur = torch.nn.DataParallel (model_restoration_deblur) \n",
    "model_restoration_deblur.cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4247e9",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "The restored model is validate using the validation dataset (val_loader). For each batch of validation data, the model's evaluation mode is set using .eval(), and the input data is passed through the restoration model to obtain the restored output. The PSNR is computed between the input and ground_truth images, as well as between the restored output and the ground_truth. After processing all validation batches, the average PSNR values for the dataset and the model's initial output are computed and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e09f741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: Input & GT =>24.9710 dB \n",
      "PSNR: Model_init & GT =>33.8368 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if do_validation :\n",
    "    with torch.no_grad():\n",
    "        model_restoration_deblur.eval()\n",
    "        psnr_dataset = []\n",
    "        psnr_model_init = []\n",
    "        for ii, data_val in enumerate(tqdm(val_loader ), 0):\n",
    "            target = data_val[0].cuda()\n",
    "            input_ = data_val[1].cuda()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                restored = model_restoration_deblur(input_)\n",
    "                restored = torch.clamp(restored,0,1)  \n",
    "            psnr_dataset.append(utils.batch_PSNR(input_, target, False).item())\n",
    "            psnr_model_init.append(utils.batch_PSNR(restored, target, False).item())\n",
    "        psnr_dataset = sum(psnr_dataset)/len_valset\n",
    "        psnr_model_init = sum(psnr_model_init)/len_valset\n",
    "        print('PSNR: Input & GT =>%.4f dB'%(psnr_dataset), '\\nPSNR: Model_init & GT =>%.4f dB'%(psnr_model_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ba50f",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Iterating through epochs and batches for training the `restoration_model`. Inside the training loop, calculate the loss using the given `criterion` and perform backpropagation to update the model's parameters. At regular intervals specified by `eval_now`, compute PSNR values on the validation dataset, and save the model's best weights if the PSNR improves. After each epoch, adjust the `learning rate` using the `scheduler`. Model checkpoints are saved at regular intervals and at the best PSNR epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef377aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Start Epoch 2966 End Epoch 2968\n",
      "\n",
      "Evaluation after every 10 Iterations !!!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [01:08<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2966, Loss:0.6104, PSNR_train:33.1019dB, PSNR_val:33.8400dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [01:12<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2967, Loss:1.1711, PSNR_train:27.9317dB, PSNR_val:33.8400dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [01:16<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2968, Loss:1.1793, PSNR_train:27.5658dB, PSNR_val:33.8400dB\n",
      "------------------------------------------------------------------\n",
      "Training Completed...\n",
      "PSNR TRAIN RGB : 29.5331dB\n",
      "PSNR VAL RGB : 33.8400dB\n",
      "------------------------------------------------------------------\n",
      "Train Start:2023-08-25 01:47:56\n",
      "Train End:2023-08-25 01:51:37\n",
      "Training Time: 0 days, 0 Hs, 3 Ms, 41 S \n"
     ]
    }
   ],
   "source": [
    "print('===> Start Epoch {} End Epoch {}'.format(start_epoch, nepoch))\n",
    "best_psnr = 0\n",
    "best_epoch = 0\n",
    "best_iter = 0\n",
    "eval_now = len(train_loader)//4  \n",
    "print(\"\\nEvaluation after every {} Iterations !!!\\n\".format(eval_now))\n",
    "\n",
    "loss_scaler = NativeScaler()\n",
    "torch.cuda.empty_cache()\n",
    "start_time = time.time()   \n",
    "psnr_train_rgb_epoch=[]\n",
    "psnr_val_best_rgb_epoch=[]\n",
    "for epoch in range(start_epoch, nepoch+1):\n",
    "    epoch_loss = 0\n",
    "    train_id = 1\n",
    "    psnr_train_rgb = []\n",
    "    for i, data in enumerate(tqdm(train_loader), 0): \n",
    "        optimizer.zero_grad()\n",
    "        target = data[0].cuda()\n",
    "        input_ = data[1].cuda()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            restored = model_restoration_deblur(input_)\n",
    "            loss = criterion(restored, target)  \n",
    "        restored = torch.clamp(restored,0,1) \n",
    "        psnr_train_rgb.append(utils.batch_PSNR(restored, target, False).item())     \n",
    "        loss_scaler(loss, optimizer,parameters=model_restoration_deblur.parameters())\n",
    "        epoch_loss +=loss.item()\n",
    "        # Evaluation #\n",
    "        if (i+1)%eval_now==0 and i>0:\n",
    "            with torch.no_grad():\n",
    "                model_restoration_deblur.eval()\n",
    "                psnr_val_rgb = []\n",
    "                for ii, data_val in enumerate((val_loader), 0):\n",
    "                    target = data_val[0].cuda()\n",
    "                    input_ = data_val[1].cuda()\n",
    "                    filenames = data_val[2]\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        restored = model_restoration_deblur(input_)\n",
    "                    restored = torch.clamp(restored,0,1)  \n",
    "                    psnr_val_rgb.append(utils.batch_PSNR(restored, target, False).item())     \n",
    "                psnr_val_rgb = sum(psnr_val_rgb)/len_valset\n",
    "\n",
    "                # calculate best PSNR\n",
    "                if psnr_val_rgb > best_psnr:\n",
    "                    best_psnr = psnr_val_rgb\n",
    "                    best_epoch = epoch\n",
    "                    best_iter = i \n",
    "                    torch.save({'epoch': epoch, \n",
    "                                'state_dict': model_restoration_deblur.state_dict(),\n",
    "                                'optimizer' : optimizer.state_dict()\n",
    "                                }, os.path.join(model_dir,\"model_best.pth\"))                    \n",
    "    psnr_train_rgb=sum(psnr_train_rgb)/len_trainset\n",
    "    psnr_train_rgb_epoch.append(psnr_train_rgb)\n",
    "    psnr_val_best_rgb_epoch.append(best_psnr)\n",
    "\n",
    "    print(f\"Epoch:{epoch}, Loss:{epoch_loss:.4f}, PSNR_train:{psnr_train_rgb:.4f}dB, PSNR_val:{best_psnr:.4f}dB\")\n",
    "    scheduler.step()\n",
    "    torch.save({'epoch': epoch, \n",
    "                'state_dict': model_restoration_deblur.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict()\n",
    "                }, os.path.join(model_dir,\"model_latest.pth\"))   \n",
    "    if epoch%checkpoint == 0:\n",
    "          torch.save({'epoch': epoch, \n",
    "                    'state_dict': model_restoration_deblur.state_dict(),\n",
    "                    'optimizer' : optimizer.state_dict()\n",
    "                    }, os.path.join(model_dir,\"model_epoch_{}.pth\".format(epoch)))\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "# time calculation\n",
    "formatted_start_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(start_time))\n",
    "formatted_end_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(end_time))\n",
    "\n",
    "t_ime = end_time-start_time\n",
    "total_seconds = int(t_ime)\n",
    "seconds = total_seconds % 60\n",
    "total_minutes = total_seconds // 60\n",
    "minutes = total_minutes % 60\n",
    "total_hours = total_minutes // 60\n",
    "hours = total_hours % 24\n",
    "days = total_hours // 24\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Training Completed...\")\n",
    "print(f\"PSNR TRAIN RGB : {(sum(psnr_train_rgb_epoch)/len(psnr_train_rgb_epoch)):.4f}dB\")\n",
    "print(f\"PSNR VAL RGB : {(sum(psnr_val_best_rgb_epoch)/len(psnr_val_best_rgb_epoch)):.4f}dB\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Train Start:{}\\nTrain End:{}\\nTraining Time: {} days, {} Hs, {} Ms, {} S \"\n",
    "      .format(formatted_start_time,formatted_end_time,days,hours,minutes,seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd1804",
   "metadata": {},
   "source": [
    "## Conversion to square images\n",
    "\n",
    "The model deals with only square images and hence it should be taken care about the imput image given to the testing module. The `expand2square` function takes a PyTorch image tensor and resizes it to a square shape while maintaining its original content. It calculates a target size based on a given factor, then creates an expanded image tensor and mask. The original image is centered within the new canvas, and a mask marks the valid regions. The function returns the resized image tensor and mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2ecbccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand2square(timg,factor=16.0,ps=1):\n",
    "    _, _, h, w = timg.size()\n",
    "    X = int(math.ceil(max(h,w)/float(factor))*factor)\n",
    "    X = math.ceil(X/ps)*ps\n",
    "    img = torch.zeros(1,3,X,X).type_as(timg) # 3, h,w\n",
    "    mask = torch.zeros(1,1,X,X).type_as(timg)\n",
    "    img[:,:, ((X - h)//2):((X - h)//2 + h),((X - w)//2):((X - w)//2 + w)] = timg\n",
    "    mask[:,:, ((X - h)//2):((X - h)//2 + h),((X - w)//2):((X - w)//2 + w)].fill_(1)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a2fca6",
   "metadata": {},
   "source": [
    "## Setting Directories & Hyperparameters for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9a8d504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result directory created at D:\\YEDHU_PROJECT\\nn_project_uformer\\./development/./result_dir/testing/deblur\n"
     ]
    }
   ],
   "source": [
    "trained_path=os.path.join(directory,\"./models/training/deblur/model_best.pth\")\n",
    "result_dir=os.path.join(directory,\"./result_dir/testing/deblur\")\n",
    "\n",
    "trained_weights = trained_path\n",
    "batch_size = 1\n",
    "\n",
    "if os.path.exists(result_dir):\n",
    "    print(\"Result directory already exist.\")\n",
    "else:\n",
    "    utils.mkdir(result_dir)\n",
    "    print(\"Result directory created at {}\".format(result_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0663615",
   "metadata": {},
   "source": [
    "## Loading model for testing\n",
    "A Uformer architecture is created for the testing and is loaded with the currently generated weights during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "120414ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>Testing using weights:  D:\\YEDHU_PROJECT\\nn_project_uformer\\./development/./models/training/deblur/model_best.pth\n"
     ]
    }
   ],
   "source": [
    "model_testing = Uformer(img_size=test_ps,\n",
    "                            embed_dim=embed_dim,\n",
    "                            win_size=8,\n",
    "                            token_projection='linear',\n",
    "                            token_mlp='leff',\n",
    "                            depths=[1, 2, 8, 8, 2, 8, 8, 2, 1],\n",
    "                            modulator=True,\n",
    "                            dd_in=dd_in).cuda() \n",
    "utils.load_checkpoint(model_testing,trained_weights)\n",
    "print(\"===>Testing using weights: \", trained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6ddf1",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "The restored model is validate using the validation dataset (val_loader). For each batch of validation data, the model's evaluation mode is set using .eval(), and the input data is passed through the restoration model to obtain the restored output. The PSNR is computed between the input and ground_truth images, as well as between the restored output and the ground_truth. After processing all validation batches, the average PSNR values for the dataset and the model's initial output are computed and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73d66a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:07<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: Input & GT =>30.5877 dB \n",
      "PSNR: Model_init & GT =>36.5443 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if do_validation :\n",
    "    with torch.no_grad():\n",
    "        model_testing.eval()\n",
    "        psnr_dataset = []\n",
    "        psnr_model_init = []\n",
    "        for ii, data_val in enumerate(tqdm(test_loader ), 0):\n",
    "            target = data_val[0].cuda()\n",
    "            input_ = data_val[1].cuda()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                restored = model_testing(input_)\n",
    "                restored = torch.clamp(restored,0,1)  \n",
    "            psnr_dataset.append(utils.batch_PSNR(input_, target, False).item())\n",
    "            psnr_model_init.append(utils.batch_PSNR(restored, target, False).item())\n",
    "        psnr_dataset = sum(psnr_dataset)/len_valset\n",
    "        psnr_model_init = sum(psnr_model_init)/len_valset\n",
    "        print('PSNR: Input & GT =>%.4f dB'%(psnr_dataset), '\\nPSNR: Model_init & GT =>%.4f dB'%(psnr_model_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07ae845",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a65e939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:07<00:00,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR : 36.5441dB \n",
      "SSIM : 0.9801% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    psnr_val_rgb = []\n",
    "    ssim_val_rgb = []\n",
    "    for ii, data_test in enumerate(tqdm(test_loader), 0):   \n",
    "        rgb_gt = data_test[0].numpy().squeeze().transpose((1,2,0))\n",
    "        rgb_noisy, mask = expand2square(data_test[1].cpu(), factor=128, ps=test_ps) \n",
    "        filenames = data_test[2]\n",
    "\n",
    "        rgb_restored = model_testing(rgb_noisy.cuda())\n",
    "        rgb_restored = torch.masked_select(rgb_restored,mask.bool().cuda()).reshape(1,3,rgb_gt.shape[0],rgb_gt.shape[1])\n",
    "        rgb_restored = torch.clamp(rgb_restored,0,1).cpu().numpy().squeeze().transpose((1,2,0))\n",
    "\n",
    "        psnr = psnr_loss(rgb_restored, rgb_gt)\n",
    "        #ssim = ssim_loss(rgb_restored, rgb_gt, multichannel=True)\n",
    "        ssim = ssim_loss(rgb_restored, rgb_gt, channel_axis=2)\n",
    "        psnr_val_rgb.append(psnr)\n",
    "        ssim_val_rgb.append(ssim)\n",
    "        utils.save_img(os.path.join(result_dir,filenames[0]+'.PNG'), img_as_ubyte(rgb_restored))\n",
    "        with open(os.path.join(result_dir,'psnr_ssim.txt'),'a') as f:\n",
    "            f.write(filenames[0]+'.PNG ---->'+\"PSNR: %.4f, SSIM: %.4f] \"% (psnr, ssim)+'\\n')\n",
    "psnr_val_rgb = sum(psnr_val_rgb)/len(test_dataset)\n",
    "ssim_val_rgb = sum(ssim_val_rgb)/len(test_dataset)\n",
    "print(f\"PSNR : {(psnr_val_rgb):.4f}dB \\nSSIM : {(ssim_val_rgb):.4f}% \")\n",
    "with open(os.path.join(result_dir,'psnr_ssim.txt'),'a') as f:\n",
    "    f.write(\"Arch: Uformer_B, PSNR: %.4f, SSIM: %.4f] \"% (psnr_val_rgb, ssim_val_rgb)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca55fee6",
   "metadata": {},
   "source": [
    "## Result Summary\n",
    "\n",
    "The Uformer model fro deblur is trained and tested succesffully and we have the following set of value;  \n",
    "PSNR between input & ground truth  and between model pecdiction with input & ground befotr training, PSNR on train_data and on val_data after training, PSNR between trained model & ground truth brfore testing and PSNR between trained model & ground truth and SSIM between the trained model and ground truth after testing; with which we can evaluate the performance of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cffb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87e10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uformer",
   "language": "python",
   "name": "uformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
