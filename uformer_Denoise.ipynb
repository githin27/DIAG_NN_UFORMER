{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0957765e",
   "metadata": {},
   "source": [
    "# U_former - <font color=\"red\">Denoise</font>\n",
    "***\n",
    "\n",
    "Uformer, an image restoration model, based on Transformer Architecture aims to leverage the capability of self-attention in feature maps at multi-scale resolutions to recover more image details. \n",
    "\n",
    "Denoising in image restoration refers to the process of removing unwanted or random variations, known as noise, from a digital image which aims to enhance the quality and clarity of an image by reducing or eliminating this noise while preserving the important underlying image features.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f315d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\YEDHU_PROJECT\\nn_project_uformer\n",
      "D:\\YEDHU_PROJECT\\nn_project_uformer\n",
      "['D:\\\\YEDHU_PROJECT\\\\nn_project_uformer', 'C:\\\\Users\\\\SARATHCHANDRAKUMAR\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\python37.zip', 'C:\\\\Users\\\\SARATHCHANDRAKUMAR\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\DLLs', 'C:\\\\Users\\\\SARATHCHANDRAKUMAR\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\lib', 'C:\\\\Users\\\\SARATHCHANDRAKUMAR\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37', 'C:\\\\venvs\\\\uformer', '', 'C:\\\\venvs\\\\uformer\\\\lib\\\\site-packages', 'C:\\\\venvs\\\\uformer\\\\lib\\\\site-packages\\\\win32', 'C:\\\\venvs\\\\uformer\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\venvs\\\\uformer\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\venvs\\\\uformer\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\SARATHCHANDRAKUMAR\\\\.ipython', 'D:\\\\YEDHU_PROJECT\\\\nn_project_uformer\\\\./development']\n",
      "D:\\YEDHU_PROJECT\\nn_project_uformer\\./development/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.getcwd()\n",
    "dir_name = os.path.join(notebook_dir)\n",
    "sys.path.append(os.path.join(dir_name, './development'))\n",
    "directory = os.path.join(dir_name, './development/') \n",
    "\n",
    "print(notebook_dir)\n",
    "print(dir_name)\n",
    "print(sys.path)\n",
    "print(directory) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4771fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\venvs\\uformer\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: NVIDIA GeForce GTX 1050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e792dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import utils\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import argparse\n",
    "import options\n",
    "import math\n",
    "\n",
    "from model import Uformer\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from losses import CharbonnierLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.loader import get_training_data, get_validation_data\n",
    "from dataset import get_validation_deblur_data\n",
    "from tqdm import tqdm\n",
    "from timm.utils import NativeScaler\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr_loss\n",
    "from skimage.metrics import structural_similarity as ssim_loss\n",
    "from skimage import img_as_float32, img_as_ubyte\n",
    "from dataset.dataset_denoise import *\n",
    "from model import UNet,Uformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c649963",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "The data within SIDD Medium dataset is patches in to custom made train, validation, test datasets using `custom_dataset_denoise.py`. The generated patch data sets are stored in `/deployment/dataset/denoise/SIDD/customized_dataset` with separate folders and each of the datasets contains a ground_truth and an input folders.\n",
    "\n",
    "## Setting Directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d654ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_weights_path=os.path.join(directory, \"./models/pretrained/denoise/model_best.pth\")\n",
    "train_dir=os.path.join(directory, \"./datasets/denoise/SIDD/customized_dataset/train\")\n",
    "val_dir=os.path.join(directory, \"./datasets/denoise/SIDD/customized_dataset/val\")\n",
    "test_dir=os.path.join(directory, \"./datasets/denoise/SIDD/customized_dataset/test\")\n",
    "model_dir=os.path.join(directory, \"./models/training/denoise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd8ea55",
   "metadata": {},
   "source": [
    "## Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf277cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ps = 128   # train patch size\n",
    "val_ps = 128   # validation patch size\n",
    "test_ps = 128   # test patch size\n",
    "dd_in = 3   #dd_in\n",
    "optimizer = 'adamw'\n",
    "lr_initial = 0.0002   # learning rate\n",
    "weight_decay = 0.02\n",
    "warmup_epochs = 2\n",
    "pretrain_weights = pretrain_weights_path\n",
    "train_workers = 4\n",
    "eval_workers = 4\n",
    "checkpoint = 50\n",
    "batch_size = 1\n",
    "nepoch = 3   # number of epochs for training\n",
    "resume = True\n",
    "do_validation= True\n",
    "warmup = True\n",
    "embed_dim=32\n",
    "win_size=8\n",
    "checkpoint = 50\n",
    "\n",
    "\n",
    "#NOTE:\n",
    "#nepoch != warmup_epochs ==> causes error in scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe52c623",
   "metadata": {},
   "source": [
    "## Dataset loading\n",
    "`Training` and `validation` datasets are loaded using `get_training_data` and `get_validation_data`. The data is organized into batches using the DataLoader class, which provides parallel data loading and preprocessing. For the training dataset, shuffling is enabled to enhance randomness during training. For validation, shuffling is turned off to ensure consistent evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a09aca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading datasets\n",
      "Size of Train Dataset:40\n",
      "Size of Validation Dataset:40\n",
      "Size of Test Dataset:40 \n"
     ]
    }
   ],
   "source": [
    "print('===> Loading datasets')\n",
    "img_options_train = {'patch_size':train_ps}\n",
    "train_dataset = get_training_data(train_dir, img_options_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True,\n",
    "                          num_workers=train_workers, \n",
    "                          pin_memory=False, \n",
    "                          drop_last=False)\n",
    "val_dataset = get_validation_data(val_dir)\n",
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        num_workers=eval_workers, \n",
    "                        pin_memory=False, \n",
    "                        drop_last=False)\n",
    "test_dataset = get_validation_data(test_dir)\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False, \n",
    "                         drop_last=False)\n",
    "\n",
    "len_trainset = train_dataset.__len__()\n",
    "len_valset = val_dataset.__len__()\n",
    "len_testset = test_dataset.__len__()\n",
    "print(\"Size of Train Dataset:{}\\nSize of Validation Dataset:{}\\nSize of Test Dataset:{} \"\n",
    "      .format(len_trainset,len_valset,len_testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6de9e",
   "metadata": {},
   "source": [
    "## Loading Model Architecture\n",
    "Loading the Uformer architecture with the hyper parameters into model_restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae7de344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\venvs\\uformer\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "model_restoration = Uformer(img_size=train_ps,\n",
    "                            embed_dim=embed_dim,\n",
    "                            win_size=8,\n",
    "                            token_projection='linear',\n",
    "                            token_mlp='leff',\n",
    "                            depths=[1, 2, 8, 8, 2, 8, 8, 2, 1],\n",
    "                            modulator=True,\n",
    "                            dd_in=dd_in) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657af488",
   "metadata": {},
   "source": [
    "## Setting Optimizer & Loss\n",
    "Creating an AdamW optimizer for model parameter optimization and setting CharbonnierLoss as the loss function and move it to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515f26d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0002\n",
      "    maximize: False\n",
      "    weight_decay: 0.02\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(model_restoration.parameters(),\n",
    "                        lr=lr_initial,\n",
    "                        betas=(0.9, 0.999),\n",
    "                        eps=1e-8,\n",
    "                        weight_decay=weight_decay)\n",
    "print (optimizer)\n",
    "criterion = CharbonnierLoss().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6ddc23",
   "metadata": {},
   "source": [
    "## Setting Data Parallel\n",
    "Configure the model to use data parallelism for efficient utilization of multiple GPUs for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f38a65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_restoration = torch.nn.DataParallel (model_restoration) \n",
    "model_restoration.cuda();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc286f",
   "metadata": {},
   "source": [
    "## Setting Scheduler\n",
    "If the `warmup` flag is enabled, a combination of warmup and cosine annealing to gradually adjust the learning rate. Alternatively, if the `warmup` flag is not enabled,a step-based strategy using the StepLR scheduler is using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40571e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using warmup and cosine strategy!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\venvs\\uformer\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "if warmup:\n",
    "    print(\"Using warmup and cosine strategy!\")\n",
    "    warmup_epochs = warmup_epochs\n",
    "    scheduler_cosine = optim.lr_scheduler.CosineAnnealingLR(optimizer,nepoch-warmup_epochs, eta_min=1e-6)\n",
    "    scheduler = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=warmup_epochs, after_scheduler=scheduler_cosine)\n",
    "    scheduler.step()\n",
    "else:\n",
    "    step = 50\n",
    "    print(\"Using StepLR,step={}!\".format(step))\n",
    "    scheduler = StepLR(optimizer, step_size=step, gamma=0.5)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76add03e",
   "metadata": {},
   "source": [
    "##  Setting Resume\n",
    "If the `resume` option is enabled, the training is resume from the checkpoint. This involves loading the model's previous state, optimizer parameters, and the starting epoch and the learning rate scheduler is updated to reflect the training progress up to the resumed epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad781f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume from D:\\YEDHU_PROJECT\\nn_project_uformer\\./development/./models/pretrained/denoise/model_best.pth\n",
      "start epoch:  50\n",
      "===> Resuming Training with learning rate: 0.0002\n",
      "end epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\venvs\\uformer\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:808: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "if resume: \n",
    "    path_chk_rest = pretrain_weights \n",
    "    print(\"Resume from \"+path_chk_rest)\n",
    "    utils.load_checkpoint(model_restoration,path_chk_rest) \n",
    "    start_epoch = utils.load_start_epoch(path_chk_rest) + 1 \n",
    "    lr = utils.load_optim(optimizer, path_chk_rest)\n",
    "    print(\"start epoch: \",start_epoch)\n",
    "    for i in range(1, start_epoch):\n",
    "        scheduler.step()\n",
    "    new_lr = scheduler.get_last_lr()[0]\n",
    "    print(\"===> Resuming Training with learning rate:\", new_lr)\n",
    "    nepoch=start_epoch+nepoch-1\n",
    "    print(f\"end epoch: {nepoch}\")\n",
    "else:\n",
    "    start_epoch = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef310692",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "The restored model is validate using the validation dataset (val_loader). For each batch of validation data, the model's evaluation mode is set using .eval(), and the input data is passed through the restoration model to obtain the restored output. The PSNR is computed between the input and ground_truth images, as well as between the restored output and the ground_truth. After processing all validation batches, the average PSNR values for the dataset and the model's initial output are computed and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c6db6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:19<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: Input & GT =>32.1453 dB \n",
      "PSNR: Model_init & GT =>47.3363 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if do_validation :\n",
    "    with torch.no_grad():\n",
    "        model_restoration.eval()\n",
    "        psnr_dataset = []\n",
    "        psnr_model_init = []\n",
    "        for ii, data_val in enumerate(tqdm(val_loader ), 0):\n",
    "            target = data_val[0].cuda()\n",
    "            input_ = data_val[1].cuda()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                restored = model_restoration(input_)\n",
    "                restored = torch.clamp(restored,0,1)  \n",
    "            psnr_dataset.append(utils.batch_PSNR(input_, target, False).item())\n",
    "            psnr_model_init.append(utils.batch_PSNR(restored, target, False).item())\n",
    "        psnr_dataset = sum(psnr_dataset)/len_valset\n",
    "        psnr_model_init = sum(psnr_model_init)/len_valset\n",
    "        print('PSNR: Input & GT =>%.4f dB'%(psnr_dataset), '\\nPSNR: Model_init & GT =>%.4f dB'%(psnr_model_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f3817",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Iterating through epochs and batches for training the `restoration_model`. Inside the training loop, calculate the loss using the given `criterion` and perform backpropagation to update the model's parameters. At regular intervals specified by `eval_now`, compute PSNR values on the validation dataset, and save the model's best weights if the PSNR improves. After each epoch, adjust the `learning rate` using the `scheduler`. Model checkpoints are saved at regular intervals and at the best PSNR epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb8182",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Start Epoch 50 End Epoch 52\n",
      "\n",
      "Evaluation after every 10 Iterations !!!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [02:02<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:50, Loss:0.1328, PSNR_train:48.5432dB, PSNR_val:47.3481dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [02:09<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:51, Loss:0.1370, PSNR_train:48.1062dB, PSNR_val:47.3481dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▌                                                           | 11/40 [00:38<02:35,  5.35s/it]"
     ]
    }
   ],
   "source": [
    "print('===> Start Epoch {} End Epoch {}'.format(start_epoch, nepoch))\n",
    "best_psnr = 0\n",
    "best_epoch = 0\n",
    "best_iter = 0\n",
    "eval_now = len(train_loader)//4  \n",
    "print(\"\\nEvaluation after every {} Iterations !!!\\n\".format(eval_now))\n",
    "\n",
    "loss_scaler = NativeScaler()\n",
    "torch.cuda.empty_cache()\n",
    "start_time = time.time()   \n",
    "psnr_train_rgb_epoch=[]\n",
    "psnr_val_best_rgb_epoch=[]\n",
    "for epoch in range(start_epoch, nepoch+1):\n",
    "    epoch_loss = 0\n",
    "    train_id = 1\n",
    "    psnr_train_rgb = []\n",
    "    for i, data in enumerate(tqdm(train_loader), 0): \n",
    "        optimizer.zero_grad()\n",
    "        target = data[0].cuda()\n",
    "        input_ = data[1].cuda()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            restored = model_restoration(input_)\n",
    "            loss = criterion(restored, target)  \n",
    "        restored = torch.clamp(restored,0,1) \n",
    "        psnr_train_rgb.append(utils.batch_PSNR(restored, target, False).item())     \n",
    "        loss_scaler(loss, optimizer,parameters=model_restoration.parameters())\n",
    "        epoch_loss +=loss.item()\n",
    "        # Evaluation #\n",
    "        if (i+1)%eval_now==0 and i>0:\n",
    "            with torch.no_grad():\n",
    "                model_restoration.eval()\n",
    "                psnr_val_rgb = []\n",
    "                for ii, data_val in enumerate((val_loader), 0):\n",
    "                    target = data_val[0].cuda()\n",
    "                    input_ = data_val[1].cuda()\n",
    "                    filenames = data_val[2]\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        restored = model_restoration(input_)\n",
    "                    restored = torch.clamp(restored,0,1)  \n",
    "                    psnr_val_rgb.append(utils.batch_PSNR(restored, target, False).item())     \n",
    "                psnr_val_rgb = sum(psnr_val_rgb)/len_valset\n",
    "\n",
    "                # calculate best PSNR\n",
    "                if psnr_val_rgb > best_psnr:\n",
    "                    best_psnr = psnr_val_rgb\n",
    "                    best_epoch = epoch\n",
    "                    best_iter = i \n",
    "                    torch.save({'epoch': epoch, \n",
    "                                'state_dict': model_restoration.state_dict(),\n",
    "                                'optimizer' : optimizer.state_dict()\n",
    "                                }, os.path.join(model_dir,\"model_best.pth\"))                    \n",
    "    psnr_train_rgb=sum(psnr_train_rgb)/len_trainset\n",
    "    psnr_train_rgb_epoch.append(psnr_train_rgb)\n",
    "    psnr_val_best_rgb_epoch.append(best_psnr)\n",
    "\n",
    "    print(f\"Epoch:{epoch}, Loss:{epoch_loss:.4f}, PSNR_train:{psnr_train_rgb:.4f}dB, PSNR_val:{best_psnr:.4f}dB\")\n",
    "    scheduler.step()\n",
    "    torch.save({'epoch': epoch, \n",
    "                'state_dict': model_restoration.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict()\n",
    "                }, os.path.join(model_dir,\"model_latest.pth\"))   \n",
    "    if epoch%checkpoint == 0:\n",
    "          torch.save({'epoch': epoch, \n",
    "                    'state_dict': model_restoration.state_dict(),\n",
    "                    'optimizer' : optimizer.state_dict()\n",
    "                    }, os.path.join(model_dir,\"model_epoch_{}.pth\".format(epoch)))\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "# time calculation\n",
    "formatted_start_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(start_time))\n",
    "formatted_end_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(end_time))\n",
    "\n",
    "t_ime = end_time-start_time\n",
    "total_seconds = int(t_ime)\n",
    "seconds = total_seconds % 60\n",
    "total_minutes = total_seconds // 60\n",
    "minutes = total_minutes % 60\n",
    "total_hours = total_minutes // 60\n",
    "hours = total_hours % 24\n",
    "days = total_hours // 24\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Training Completed...\")\n",
    "print(f\"PSNR TRAIN RGB : {(sum(psnr_train_rgb_epoch)/len(psnr_train_rgb_epoch)):.4f}dB\")\n",
    "print(f\"PSNR VAL RGB : {(sum(psnr_val_best_rgb_epoch)/len(psnr_val_best_rgb_epoch)):.4f}dB\")\n",
    "print(\"------------------------------------------------------------------\")\n",
    "print(\"Train Start:{}\\nTrain End:{}\\nTraining Time: {} days, {} Hs, {} Ms, {} S \"\n",
    "      .format(formatted_start_time,formatted_end_time,days,hours,minutes,seconds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5626038",
   "metadata": {},
   "source": [
    "## Conversion to square images\n",
    "\n",
    "The model deals with only square images and hence it should be taken care about the imput image given to the testing module. The `expand2square` function takes a PyTorch image tensor and resizes it to a square shape while maintaining its original content. It calculates a target size based on a given factor, then creates an expanded image tensor and mask. The original image is centered within the new canvas, and a mask marks the valid regions. The function returns the resized image tensor and mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f01e1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand2square(timg,factor=16.0,ps=1):\n",
    "    _, _, h, w = timg.size()\n",
    "    X = int(math.ceil(max(h,w)/float(factor))*factor)\n",
    "    X = math.ceil(X/ps)*ps\n",
    "    img = torch.zeros(1,3,X,X).type_as(timg) # 3, h,w\n",
    "    mask = torch.zeros(1,1,X,X).type_as(timg)\n",
    "    img[:,:, ((X - h)//2):((X - h)//2 + h),((X - w)//2):((X - w)//2 + w)] = timg\n",
    "    mask[:,:, ((X - h)//2):((X - h)//2 + h),((X - w)//2):((X - w)//2 + w)].fill_(1)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7fc99e",
   "metadata": {},
   "source": [
    "## Setting Directories & Hyperparameters for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a65bd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result directory already exist.\n",
      "trained_path: D:\\YEDHU_PROJECT\\./CODE/deployment/./models/training/denoise/model_best.pth\n",
      "result_dir: D:\\YEDHU_PROJECT\\./CODE/deployment/./result_dir/testing/denoise\n"
     ]
    }
   ],
   "source": [
    "trained_path=os.path.join(directory,\"./models/training/denoise/model_best.pth\")\n",
    "result_dir=os.path.join(directory,\"./result_dir/testing/denoise\")\n",
    "\n",
    "trained_weights = trained_path\n",
    "batch_size = 1\n",
    "\n",
    "if os.path.exists(result_dir):\n",
    "    print(\"Result directory already exist.\")\n",
    "else:\n",
    "    utils.mkdir(result_dir)\n",
    "    print(\"Result directory created at {}\".format(result_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2f0048",
   "metadata": {},
   "source": [
    "## Loading model for testing\n",
    "A Uformer architecture is created for the testing and is loaded with the currently generated weights during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5d319c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>Testing using weights:  D:\\YEDHU_PROJECT\\./CODE/deployment/./models/training/denoise/model_best.pth\n"
     ]
    }
   ],
   "source": [
    "model_testing = Uformer(img_size=test_ps,\n",
    "                            embed_dim=embed_dim,\n",
    "                            win_size=8,\n",
    "                            token_projection='linear',\n",
    "                            token_mlp='leff',\n",
    "                            depths=[1, 2, 8, 8, 2, 8, 8, 2, 1],\n",
    "                            modulator=True,\n",
    "                            dd_in=dd_in).cuda() \n",
    "utils.load_checkpoint(model_testing,trained_weights)\n",
    "print(\"===>Testing using weights: \", trained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931600f6",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "The restored model is validate using the validation dataset (val_loader). For each batch of validation data, the model's evaluation mode is set using .eval(), and the input data is passed through the restoration model to obtain the restored output. The PSNR is computed between the input and ground_truth images, as well as between the restored output and the ground_truth. After processing all validation batches, the average PSNR values for the dataset and the model's initial output are computed and stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2203d327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:15<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: Input & GT =>32.5485 dB \n",
      "PSNR: Model_init & GT =>47.0243 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if do_validation :\n",
    "    with torch.no_grad():\n",
    "        model_testing.eval()\n",
    "        psnr_dataset = []\n",
    "        psnr_model_init = []\n",
    "        for ii, data_val in enumerate(tqdm(test_loader ), 0):\n",
    "            target = data_val[0].cuda()\n",
    "            input_ = data_val[1].cuda()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                restored = model_testing(input_)\n",
    "                restored = torch.clamp(restored,0,1)  \n",
    "            psnr_dataset.append(utils.batch_PSNR(input_, target, False).item())\n",
    "            psnr_model_init.append(utils.batch_PSNR(restored, target, False).item())\n",
    "        psnr_dataset = sum(psnr_dataset)/len_valset\n",
    "        psnr_model_init = sum(psnr_model_init)/len_valset\n",
    "        print('PSNR: Input & GT =>%.4f dB'%(psnr_dataset), '\\nPSNR: Model_init & GT =>%.4f dB'%(psnr_model_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc75c4b",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "295b4d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:18<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR:47.0271dB \n",
      "SSIM:0.9960% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    psnr_val_rgb = []\n",
    "    ssim_val_rgb = []\n",
    "    for ii, data_test in enumerate(tqdm(test_loader), 0):   \n",
    "        rgb_gt = data_test[0].numpy().squeeze().transpose((1,2,0))\n",
    "        rgb_noisy, mask = expand2square(data_test[1].cpu(), factor=128, ps=test_ps) \n",
    "        filenames = data_test[2]\n",
    "\n",
    "        rgb_restored = model_testing(rgb_noisy.cuda())\n",
    "        rgb_restored = torch.masked_select(rgb_restored,mask.bool().cuda()).reshape(1,3,rgb_gt.shape[0],rgb_gt.shape[1])\n",
    "        rgb_restored = torch.clamp(rgb_restored,0,1).cpu().numpy().squeeze().transpose((1,2,0))\n",
    "\n",
    "        psnr = psnr_loss(rgb_restored, rgb_gt)\n",
    "        #ssim = ssim_loss(rgb_restored, rgb_gt, multichannel=True)\n",
    "        ssim = ssim_loss(rgb_restored, rgb_gt, channel_axis=2)\n",
    "        psnr_val_rgb.append(psnr)\n",
    "        ssim_val_rgb.append(ssim)\n",
    "        utils.save_img(os.path.join(result_dir,filenames[0]+'.PNG'), img_as_ubyte(rgb_restored))\n",
    "        with open(os.path.join(result_dir,'psnr_ssim.txt'),'a') as f:\n",
    "            f.write(filenames[0]+'.PNG ---->'+\"PSNR: %.4f, SSIM: %.4f] \"% (psnr, ssim)+'\\n')\n",
    "psnr_val_rgb = sum(psnr_val_rgb)/len(test_dataset)\n",
    "ssim_val_rgb = sum(ssim_val_rgb)/len(test_dataset)\n",
    "print(f\"PSNR : {(psnr_val_rgb):.4f}dB \\nSSIM : {(ssim_val_rgb):.4f}% \")\n",
    "with open(os.path.join(result_dir,'psnr_ssim.txt'),'a') as f:\n",
    "    f.write(\"Arch: Uformer_B, PSNR: %.4f, SSIM: %.4f] \"% (psnr_val_rgb, ssim_val_rgb)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff398796",
   "metadata": {},
   "source": [
    "## Result Summary\n",
    "\n",
    "The Uformer model fro deblur is trained and tested succesffully and we have the following set of value;  \n",
    "PSNR between input & ground truth  and between model pecdiction with input & ground befotr training, PSNR on train_data and on val_data after training, PSNR between trained model & ground truth brfore testing and PSNR between trained model & ground truth and SSIM between the trained model and ground truth after testing; with which we can evaluate the performance of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de86288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffd70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f48935a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c685717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35df959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uformer",
   "language": "python",
   "name": "uformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
